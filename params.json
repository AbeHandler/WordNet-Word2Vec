{"name":"Wordnet-word2vec","tagline":"An empirical study of semantic similarity in WordNet and Word2Vec","body":"###An empirical study of semantic similarity in WordNet and Word2Vec\r\n#####Abram Handler | Master's Thesis: University of New Orleans, Fall 2014\r\n\r\n####Project\r\nWord2Vec is a new unsupervised system for determining the semantic distance between words. For instance, after learning from billions of web pages, Word2Vec reports that the words Chinese river are semantically close to the word Yangtze. Such results have attracted lots of recent attention: over 100 researchers have cited Word2Vec since its publication in 2013. Yet certain aspects of the system’s output are poorly understood. \r\n\r\nIn particular:\r\n\r\n1. Word2Vec does not label particular semantic relationships between words – like the synonomy between cold and chilly or the meronomy between wheel and car. Instead, it assigns a number between 0 and 1, indicating the semantic distance between two words. As Word2Vec's creator's note: “there can be many different types of similarities.” [2] This opens an unknon question: what sorts of semantic similarities does Word2Vec uncover?\r\n\r\n2. Word2Vec can generate ranked lists showing which words are closer are further way in a semantic model. For example, Word2Vec says that grand-master is 3rd from the word chess, while Muay Thai kickboxing is 997th. What is the probability that two words that are k-apart in Word2Vec stand in some formal specific semantic relationship?\r\n\r\nThis study seeks to answer such questions by comparing Word2Vec’s output with WordNet – a large, human-curated “lexical database” [3] and the most-frequently cited “lexiographic resource” [4] in English.\r\n\r\n####Results\r\n\r\nPick a word from the Reuters corpus. Get the 200 closest words in Word2Vec. How are these 200 words semantically related to the original word?\r\n\r\n![All results](images/total.png)\r\n\r\n####Files\r\n\r\n`main.sh` Primary driver for the application. Use ./main.sh to run the experiment and generate results\r\n\r\n`experiment.py` Runs the experiment\r\n\r\n`process_results.sh` Calculates totals used to show final results\r\n\r\n`tester.py` Some unit tests\r\n\r\n`wordnetchecker.py` Finds the average numbers of each relation in WordNet\r\n\r\n####Dependencies\r\n\r\n* **NLTK 3.0.0**\r\n* **Gensim 0.10.2**\r\n* **numpy 1.9.0**\r\n* **Word vectors from Google news corpus** [downloadable here](https://code.google.com/p/word2vec/).\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}